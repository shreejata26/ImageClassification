{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##imports\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing.image import ImageDataGenerator \n",
    "from keras.layers import BatchNormalization\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pathlib\n",
    "import zipfile\n",
    "import cv2\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VfEEBiQQQpU0"
   },
   "outputs": [],
   "source": [
    "data_root=pathlib.Path('/content/drive/My Drive/101_ObjectCategories_resized')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2byNnZNN9yt2"
   },
   "outputs": [],
   "source": [
    "labels = []\n",
    "# i=1\n",
    "for item in data_root.glob('*'):\n",
    "  if item.name!='.DS_Store':\n",
    "    # print(item.name)\n",
    "    labels.append(item.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4JgpP3P091u3"
   },
   "outputs": [],
   "source": [
    "labels_lst = []\n",
    "training_data = []\n",
    "i=0\n",
    "for category in labels:\n",
    "  \n",
    "  path = os.path.join(data_root,category)  \n",
    " \n",
    "  labels_lst.append([item.name,i])\n",
    "  \n",
    "  for img in os.listdir(path):  \n",
    "      img_array = cv2.imread(os.path.join(path,img)) \n",
    "      training_data.append([img_array,i])\n",
    "       \n",
    "  i=i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9IRoZuDr9_WO"
   },
   "outputs": [],
   "source": [
    "pickle_out = open(\"/content/drive/My Drive/training_data.pickle\",\"wb\")\n",
    "pickle.dump(training_data, pickle_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "NgYUHk3nMPpK",
    "outputId": "d2e44dbc-1a00-4a6e-a768-db1ac93bdf84"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "##prepare data\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cgL_OThfMTbV"
   },
   "outputs": [],
   "source": [
    "\n",
    "pickle_in = open(\"/content/drive/My Drive/training_data.pickle\",\"rb\")\n",
    "training_data = pickle.load(pickle_in)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GKjJ8KSLMb_9"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "random.shuffle(training_data)\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "for features,label in training_data:\n",
    "    X.append(features)\n",
    "    y.append(label)\n",
    "#normalize image array\n",
    "X = (np.asarray(X, dtype=np.float32))/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cXv2wW2uMfLd"
   },
   "outputs": [],
   "source": [
    "##one-hot encode labels\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from keras import utils\n",
    "from keras.utils import np_utils\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "# encode class values as integers\n",
    "encoder = preprocessing.LabelEncoder()\n",
    "encoder.fit(y)\n",
    "encoded_Y = encoder.transform(y)\n",
    "# convert integers to dummy variables (i.e. one hot encoded)\n",
    "dummy_y = np_utils.to_categorical(encoded_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "f44oGF7iMhtd",
    "outputId": "289883c5-8823-41d5-ef40-daad6f9103ab"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8677, 64, 64, 3)"
      ]
     },
     "execution_count": 23,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 425
    },
    "colab_type": "code",
    "id": "iFuBiENUMk1b",
    "outputId": "af9b4742-e830-4676-80eb-83f1324e780d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_25\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_52 (Conv2D)           (None, 64, 64, 32)        2432      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_50 (MaxPooling (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_53 (Conv2D)           (None, 16, 16, 64)        51264     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_51 (MaxPooling (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_23 (Flatten)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_69 (Dense)             (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_70 (Dense)             (None, 84)                86100     \n",
      "_________________________________________________________________\n",
      "dense_71 (Dense)             (None, 101)               8585      \n",
      "=================================================================\n",
      "Total params: 1,197,981\n",
      "Trainable params: 1,197,981\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "##LeNet5-baseline\n",
    "\n",
    "model_base = models.Sequential()\n",
    "model_base.add(layers.Conv2D(32, (5, 5), activation='relu',input_shape =(64, 64, 3), padding='same'))\n",
    "model_base.add(layers.MaxPooling2D((4, 4),padding='valid',strides=4))\n",
    "\n",
    "model_base.add(layers.Conv2D(64, (5, 5), activation='relu', padding='same'))\n",
    "model_base.add(layers.MaxPooling2D((4, 4), padding='same',strides=4))\n",
    "\n",
    "model_base.add(layers.Flatten())\n",
    "model_base.add(Dense(1024, activation='relu'))\n",
    "model_base.add(Dense(84, activation='relu'))\n",
    "model_base.add(Dense(101, activation='softmax'))\n",
    "model_base.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "q9vvcXdoMsIs",
    "outputId": "82d91740-a300-4d65-e9f9-f5df77172a6e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7809 samples, validate on 868 samples\n",
      "Epoch 1/100\n",
      "7809/7809 [==============================] - 2s 298us/sample - loss: 4.4038 - acc: 0.0893 - val_loss: 4.2774 - val_acc: 0.1025\n",
      "Epoch 2/100\n",
      "7809/7809 [==============================] - 1s 120us/sample - loss: 4.1841 - acc: 0.1593 - val_loss: 4.1014 - val_acc: 0.2189\n",
      "Epoch 3/100\n",
      "7809/7809 [==============================] - 1s 120us/sample - loss: 3.9694 - acc: 0.2276 - val_loss: 3.8588 - val_acc: 0.2327\n",
      "Epoch 4/100\n",
      "7809/7809 [==============================] - 1s 122us/sample - loss: 3.7371 - acc: 0.2415 - val_loss: 3.6947 - val_acc: 0.2408\n",
      "Epoch 5/100\n",
      "7809/7809 [==============================] - 1s 119us/sample - loss: 3.5749 - acc: 0.2633 - val_loss: 3.5194 - val_acc: 0.2546\n",
      "Epoch 6/100\n",
      "7809/7809 [==============================] - 1s 120us/sample - loss: 3.4167 - acc: 0.2847 - val_loss: 3.3861 - val_acc: 0.2984\n",
      "Epoch 7/100\n",
      "7809/7809 [==============================] - 1s 119us/sample - loss: 3.3090 - acc: 0.3112 - val_loss: 3.2927 - val_acc: 0.3111\n",
      "Epoch 8/100\n",
      "7809/7809 [==============================] - 1s 120us/sample - loss: 3.1903 - acc: 0.3318 - val_loss: 3.2279 - val_acc: 0.3353\n",
      "Epoch 9/100\n",
      "7809/7809 [==============================] - 1s 120us/sample - loss: 3.0770 - acc: 0.3523 - val_loss: 3.0842 - val_acc: 0.3721\n",
      "Epoch 10/100\n",
      "7809/7809 [==============================] - 1s 121us/sample - loss: 2.9838 - acc: 0.3706 - val_loss: 3.0051 - val_acc: 0.3859\n",
      "Epoch 11/100\n",
      "7809/7809 [==============================] - 1s 122us/sample - loss: 2.8644 - acc: 0.3916 - val_loss: 2.9231 - val_acc: 0.3952\n",
      "Epoch 12/100\n",
      "7809/7809 [==============================] - 1s 120us/sample - loss: 2.7642 - acc: 0.4065 - val_loss: 2.8274 - val_acc: 0.4021\n",
      "Epoch 13/100\n",
      "7809/7809 [==============================] - 1s 122us/sample - loss: 2.6663 - acc: 0.4196 - val_loss: 2.7850 - val_acc: 0.4171\n",
      "Epoch 14/100\n",
      "7809/7809 [==============================] - 1s 121us/sample - loss: 2.5951 - acc: 0.4351 - val_loss: 2.7749 - val_acc: 0.4124\n",
      "Epoch 15/100\n",
      "7809/7809 [==============================] - 1s 120us/sample - loss: 2.5124 - acc: 0.4455 - val_loss: 2.6512 - val_acc: 0.4401\n",
      "Epoch 16/100\n",
      "7809/7809 [==============================] - 1s 121us/sample - loss: 2.4314 - acc: 0.4620 - val_loss: 2.6387 - val_acc: 0.4389\n",
      "Epoch 17/100\n",
      "7809/7809 [==============================] - 1s 122us/sample - loss: 2.3705 - acc: 0.4723 - val_loss: 2.5406 - val_acc: 0.4516\n",
      "Epoch 18/100\n",
      "7809/7809 [==============================] - 1s 124us/sample - loss: 2.2999 - acc: 0.4855 - val_loss: 2.4974 - val_acc: 0.4735\n",
      "Epoch 19/100\n",
      "7809/7809 [==============================] - 1s 122us/sample - loss: 2.2543 - acc: 0.4943 - val_loss: 2.4726 - val_acc: 0.4574\n",
      "Epoch 20/100\n",
      "7809/7809 [==============================] - 1s 122us/sample - loss: 2.1921 - acc: 0.5045 - val_loss: 2.4282 - val_acc: 0.4724\n",
      "Epoch 21/100\n",
      "7809/7809 [==============================] - 1s 123us/sample - loss: 2.1269 - acc: 0.5216 - val_loss: 2.4213 - val_acc: 0.4700\n",
      "Epoch 22/100\n",
      "7809/7809 [==============================] - 1s 123us/sample - loss: 2.0973 - acc: 0.5245 - val_loss: 2.3875 - val_acc: 0.4700\n",
      "Epoch 23/100\n",
      "7809/7809 [==============================] - 1s 122us/sample - loss: 2.0519 - acc: 0.5302 - val_loss: 2.3270 - val_acc: 0.4839\n",
      "Epoch 24/100\n",
      "7809/7809 [==============================] - 1s 123us/sample - loss: 1.9846 - acc: 0.5459 - val_loss: 2.3055 - val_acc: 0.4919\n",
      "Epoch 25/100\n",
      "7809/7809 [==============================] - 1s 124us/sample - loss: 1.9435 - acc: 0.5533 - val_loss: 2.2833 - val_acc: 0.4862\n",
      "Epoch 26/100\n",
      "7809/7809 [==============================] - 1s 123us/sample - loss: 1.8984 - acc: 0.5693 - val_loss: 2.2605 - val_acc: 0.5012\n",
      "Epoch 27/100\n",
      "7809/7809 [==============================] - 1s 121us/sample - loss: 1.8828 - acc: 0.5687 - val_loss: 2.2331 - val_acc: 0.5035\n",
      "Epoch 28/100\n",
      "7809/7809 [==============================] - 1s 125us/sample - loss: 1.8258 - acc: 0.5818 - val_loss: 2.1786 - val_acc: 0.5092\n",
      "Epoch 29/100\n",
      "7809/7809 [==============================] - 1s 126us/sample - loss: 1.7999 - acc: 0.5836 - val_loss: 2.2303 - val_acc: 0.5092\n",
      "Epoch 30/100\n",
      "7809/7809 [==============================] - 1s 124us/sample - loss: 1.7645 - acc: 0.5919 - val_loss: 2.1905 - val_acc: 0.5092\n",
      "Epoch 31/100\n",
      "7809/7809 [==============================] - 1s 128us/sample - loss: 1.7342 - acc: 0.5942 - val_loss: 2.1409 - val_acc: 0.5092\n",
      "Epoch 32/100\n",
      "7809/7809 [==============================] - 1s 122us/sample - loss: 1.6957 - acc: 0.6060 - val_loss: 2.1266 - val_acc: 0.5196\n",
      "Epoch 33/100\n",
      "7809/7809 [==============================] - 1s 122us/sample - loss: 1.6489 - acc: 0.6148 - val_loss: 2.0941 - val_acc: 0.5242\n",
      "Epoch 34/100\n",
      "7809/7809 [==============================] - 1s 122us/sample - loss: 1.6010 - acc: 0.6266 - val_loss: 2.1069 - val_acc: 0.5219\n",
      "Epoch 35/100\n",
      "7809/7809 [==============================] - 1s 124us/sample - loss: 1.6004 - acc: 0.6272 - val_loss: 2.0582 - val_acc: 0.5369\n",
      "Epoch 36/100\n",
      "7809/7809 [==============================] - 1s 121us/sample - loss: 1.5816 - acc: 0.6303 - val_loss: 2.0374 - val_acc: 0.5346\n",
      "Epoch 37/100\n",
      "7809/7809 [==============================] - 1s 123us/sample - loss: 1.5237 - acc: 0.6446 - val_loss: 2.0477 - val_acc: 0.5403\n",
      "Epoch 38/100\n",
      "7809/7809 [==============================] - 1s 123us/sample - loss: 1.5099 - acc: 0.6446 - val_loss: 2.0149 - val_acc: 0.5461\n",
      "Epoch 39/100\n",
      "7809/7809 [==============================] - 1s 121us/sample - loss: 1.4703 - acc: 0.6557 - val_loss: 1.9934 - val_acc: 0.5518\n",
      "Epoch 40/100\n",
      "7809/7809 [==============================] - 1s 123us/sample - loss: 1.4462 - acc: 0.6598 - val_loss: 1.9929 - val_acc: 0.5472\n",
      "Epoch 41/100\n",
      "7809/7809 [==============================] - 1s 122us/sample - loss: 1.4022 - acc: 0.6681 - val_loss: 1.9992 - val_acc: 0.5530\n",
      "Epoch 42/100\n",
      "7809/7809 [==============================] - 1s 123us/sample - loss: 1.4169 - acc: 0.6638 - val_loss: 1.9718 - val_acc: 0.5576\n",
      "Epoch 43/100\n",
      "7809/7809 [==============================] - 1s 122us/sample - loss: 1.3822 - acc: 0.6723 - val_loss: 1.9988 - val_acc: 0.5438\n",
      "Epoch 44/100\n",
      "7809/7809 [==============================] - 1s 122us/sample - loss: 1.3480 - acc: 0.6827 - val_loss: 1.9936 - val_acc: 0.5541\n",
      "Epoch 45/100\n",
      "7809/7809 [==============================] - 1s 122us/sample - loss: 1.3352 - acc: 0.6846 - val_loss: 1.9588 - val_acc: 0.5565\n",
      "Epoch 46/100\n",
      "7809/7809 [==============================] - 1s 124us/sample - loss: 1.3056 - acc: 0.6856 - val_loss: 1.9458 - val_acc: 0.5611\n",
      "Epoch 47/100\n",
      "7809/7809 [==============================] - 1s 125us/sample - loss: 1.2712 - acc: 0.6939 - val_loss: 1.9518 - val_acc: 0.5703\n",
      "Epoch 48/100\n",
      "7809/7809 [==============================] - 1s 127us/sample - loss: 1.2572 - acc: 0.6994 - val_loss: 1.9268 - val_acc: 0.5541\n",
      "Epoch 49/100\n",
      "7809/7809 [==============================] - 1s 121us/sample - loss: 1.2226 - acc: 0.7087 - val_loss: 1.9431 - val_acc: 0.5634\n",
      "Epoch 50/100\n",
      "7809/7809 [==============================] - 1s 122us/sample - loss: 1.2146 - acc: 0.7078 - val_loss: 1.9442 - val_acc: 0.5622\n",
      "Epoch 51/100\n",
      "7809/7809 [==============================] - 1s 124us/sample - loss: 1.1834 - acc: 0.7117 - val_loss: 1.9075 - val_acc: 0.5703\n",
      "Epoch 52/100\n",
      "7809/7809 [==============================] - 1s 122us/sample - loss: 1.1751 - acc: 0.7155 - val_loss: 1.8944 - val_acc: 0.5737\n",
      "Epoch 53/100\n",
      "7809/7809 [==============================] - 1s 122us/sample - loss: 1.1432 - acc: 0.7231 - val_loss: 1.9197 - val_acc: 0.5622\n",
      "Epoch 54/100\n",
      "7809/7809 [==============================] - 1s 122us/sample - loss: 1.1294 - acc: 0.7224 - val_loss: 1.8897 - val_acc: 0.5806\n",
      "Epoch 55/100\n",
      "7809/7809 [==============================] - 1s 122us/sample - loss: 1.1144 - acc: 0.7297 - val_loss: 1.9180 - val_acc: 0.5565\n",
      "Epoch 56/100\n",
      "7809/7809 [==============================] - 1s 125us/sample - loss: 1.1064 - acc: 0.7295 - val_loss: 1.9100 - val_acc: 0.5714\n",
      "Epoch 57/100\n",
      "7809/7809 [==============================] - 1s 123us/sample - loss: 1.0636 - acc: 0.7375 - val_loss: 1.9618 - val_acc: 0.5530\n",
      "Epoch 58/100\n",
      "7809/7809 [==============================] - 1s 121us/sample - loss: 1.0347 - acc: 0.7507 - val_loss: 1.9083 - val_acc: 0.5588\n",
      "Epoch 59/100\n",
      "7809/7809 [==============================] - 1s 121us/sample - loss: 1.0401 - acc: 0.7431 - val_loss: 1.9184 - val_acc: 0.5657\n",
      "Epoch 60/100\n",
      "7809/7809 [==============================] - 1s 127us/sample - loss: 1.0093 - acc: 0.7493 - val_loss: 1.8897 - val_acc: 0.5829\n",
      "Epoch 61/100\n",
      "7809/7809 [==============================] - 1s 126us/sample - loss: 0.9949 - acc: 0.7558 - val_loss: 1.8633 - val_acc: 0.5749\n",
      "Epoch 62/100\n",
      "7809/7809 [==============================] - 1s 122us/sample - loss: 0.9751 - acc: 0.7618 - val_loss: 1.8899 - val_acc: 0.5783\n",
      "Epoch 63/100\n",
      "7809/7809 [==============================] - 1s 122us/sample - loss: 0.9680 - acc: 0.7657 - val_loss: 1.8374 - val_acc: 0.5876\n",
      "Epoch 64/100\n",
      "7809/7809 [==============================] - 1s 122us/sample - loss: 0.9138 - acc: 0.7796 - val_loss: 1.9304 - val_acc: 0.5703\n",
      "Epoch 65/100\n",
      "7809/7809 [==============================] - 1s 122us/sample - loss: 0.9028 - acc: 0.7777 - val_loss: 1.8736 - val_acc: 0.5818\n",
      "Epoch 66/100\n",
      "7809/7809 [==============================] - 1s 121us/sample - loss: 0.8970 - acc: 0.7799 - val_loss: 1.9552 - val_acc: 0.5691\n",
      "Epoch 67/100\n",
      "7809/7809 [==============================] - 1s 122us/sample - loss: 0.8993 - acc: 0.7803 - val_loss: 1.8566 - val_acc: 0.5783\n",
      "Epoch 68/100\n",
      "7809/7809 [==============================] - 1s 121us/sample - loss: 0.8600 - acc: 0.7922 - val_loss: 1.8898 - val_acc: 0.5818\n",
      "Epoch 69/100\n",
      "7809/7809 [==============================] - 1s 124us/sample - loss: 0.8561 - acc: 0.7888 - val_loss: 1.8554 - val_acc: 0.5899\n",
      "Epoch 70/100\n",
      "7809/7809 [==============================] - 1s 121us/sample - loss: 0.8166 - acc: 0.8006 - val_loss: 1.9001 - val_acc: 0.5864\n",
      "Epoch 71/100\n",
      "7809/7809 [==============================] - 1s 123us/sample - loss: 0.8233 - acc: 0.7984 - val_loss: 1.8490 - val_acc: 0.5933\n",
      "Epoch 72/100\n",
      "7809/7809 [==============================] - 1s 120us/sample - loss: 0.7944 - acc: 0.8080 - val_loss: 1.8921 - val_acc: 0.5806\n",
      "Epoch 73/100\n",
      "7809/7809 [==============================] - 1s 122us/sample - loss: 0.7781 - acc: 0.8133 - val_loss: 1.9002 - val_acc: 0.5783\n",
      "Epoch 74/100\n",
      "7809/7809 [==============================] - 1s 124us/sample - loss: 0.7431 - acc: 0.8235 - val_loss: 1.8625 - val_acc: 0.5922\n",
      "Epoch 75/100\n",
      "7809/7809 [==============================] - 1s 121us/sample - loss: 0.7338 - acc: 0.8229 - val_loss: 1.8835 - val_acc: 0.5887\n",
      "Epoch 76/100\n",
      "7809/7809 [==============================] - 1s 122us/sample - loss: 0.7234 - acc: 0.8221 - val_loss: 1.9230 - val_acc: 0.5841\n",
      "Epoch 77/100\n",
      "7809/7809 [==============================] - 1s 122us/sample - loss: 0.7444 - acc: 0.8171 - val_loss: 1.8808 - val_acc: 0.5853\n",
      "Epoch 78/100\n",
      "7809/7809 [==============================] - 1s 121us/sample - loss: 0.7178 - acc: 0.8255 - val_loss: 1.8675 - val_acc: 0.5933\n",
      "Epoch 79/100\n",
      "7809/7809 [==============================] - 1s 121us/sample - loss: 0.6733 - acc: 0.8369 - val_loss: 1.8662 - val_acc: 0.5945\n",
      "Epoch 80/100\n",
      "7809/7809 [==============================] - 1s 122us/sample - loss: 0.6642 - acc: 0.8420 - val_loss: 1.8997 - val_acc: 0.5991\n",
      "Epoch 81/100\n",
      "7809/7809 [==============================] - 1s 123us/sample - loss: 0.6615 - acc: 0.8371 - val_loss: 1.8495 - val_acc: 0.5749\n",
      "Epoch 82/100\n",
      "7809/7809 [==============================] - 1s 123us/sample - loss: 0.6102 - acc: 0.8582 - val_loss: 1.8700 - val_acc: 0.5956\n",
      "Epoch 83/100\n",
      "7809/7809 [==============================] - 1s 125us/sample - loss: 0.5906 - acc: 0.8662 - val_loss: 1.9104 - val_acc: 0.5979\n",
      "Epoch 84/100\n",
      "7809/7809 [==============================] - 1s 121us/sample - loss: 0.5959 - acc: 0.8585 - val_loss: 1.9346 - val_acc: 0.5864\n",
      "Epoch 85/100\n",
      "7809/7809 [==============================] - 1s 122us/sample - loss: 0.6304 - acc: 0.8447 - val_loss: 1.8894 - val_acc: 0.5853\n",
      "Epoch 86/100\n",
      "7809/7809 [==============================] - 1s 123us/sample - loss: 0.5874 - acc: 0.8616 - val_loss: 1.9079 - val_acc: 0.5910\n",
      "Epoch 87/100\n",
      "7809/7809 [==============================] - 1s 122us/sample - loss: 0.5601 - acc: 0.8666 - val_loss: 1.9317 - val_acc: 0.5887\n",
      "Epoch 88/100\n",
      "7809/7809 [==============================] - 1s 125us/sample - loss: 0.5512 - acc: 0.8717 - val_loss: 1.8907 - val_acc: 0.5979\n",
      "Epoch 89/100\n",
      "7809/7809 [==============================] - 1s 122us/sample - loss: 0.5322 - acc: 0.8746 - val_loss: 1.9045 - val_acc: 0.6048\n",
      "Epoch 90/100\n",
      "7809/7809 [==============================] - 1s 121us/sample - loss: 0.5207 - acc: 0.8774 - val_loss: 1.8904 - val_acc: 0.5979\n",
      "Epoch 91/100\n",
      "7809/7809 [==============================] - 1s 122us/sample - loss: 0.5002 - acc: 0.8826 - val_loss: 1.9411 - val_acc: 0.6048\n",
      "Epoch 92/100\n",
      "7809/7809 [==============================] - 1s 123us/sample - loss: 0.4851 - acc: 0.8890 - val_loss: 1.9590 - val_acc: 0.5979\n",
      "Epoch 93/100\n",
      "7809/7809 [==============================] - 1s 125us/sample - loss: 0.4715 - acc: 0.8942 - val_loss: 1.9283 - val_acc: 0.6048\n",
      "Epoch 94/100\n",
      "7809/7809 [==============================] - 1s 122us/sample - loss: 0.4948 - acc: 0.8810 - val_loss: 1.9406 - val_acc: 0.5910\n",
      "Epoch 95/100\n",
      "7809/7809 [==============================] - 1s 121us/sample - loss: 0.4519 - acc: 0.8968 - val_loss: 1.9340 - val_acc: 0.6014\n",
      "Epoch 96/100\n",
      "7809/7809 [==============================] - 1s 121us/sample - loss: 0.4401 - acc: 0.8993 - val_loss: 1.9415 - val_acc: 0.5968\n",
      "Epoch 97/100\n",
      "7809/7809 [==============================] - 1s 122us/sample - loss: 0.4027 - acc: 0.9143 - val_loss: 1.9653 - val_acc: 0.5956\n",
      "Epoch 98/100\n",
      "7809/7809 [==============================] - 1s 123us/sample - loss: 0.3980 - acc: 0.9139 - val_loss: 1.9754 - val_acc: 0.6083\n",
      "Epoch 99/100\n",
      "7809/7809 [==============================] - 1s 121us/sample - loss: 0.4046 - acc: 0.9102 - val_loss: 1.9722 - val_acc: 0.6002\n",
      "Epoch 100/100\n",
      "7809/7809 [==============================] - 1s 121us/sample - loss: 0.3821 - acc: 0.9177 - val_loss: 1.9712 - val_acc: 0.5968\n"
     ]
    }
   ],
   "source": [
    "from keras import optimizers\n",
    "from keras.optimizers import Adam\n",
    "opt = keras.optimizers.Adam(learning_rate=0.0001)\n",
    "model_base.compile(loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "              optimizer=opt,\n",
    "              metrics = ['accuracy'])\n",
    "\n",
    "history = model_base.fit(X, dummy_y, epochs=100, validation_split=0.1,batch_size=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "colab_type": "code",
    "id": "zrqkZcVdMw9W",
    "outputId": "f1f7a19b-8e6e-4596-b498-ca2d7e59abc8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fe3ac83fe80>"
      ]
     },
     "execution_count": 77,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEKCAYAAAAfGVI8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n+3/n28FnzSmCiwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "####evaluate model\n",
    "plt.plot(history.history['acc'], label='accuracy')\n",
    "plt.plot(history.history['val_acc'], label = 'val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0, 1])\n",
    "plt.legend(loc='lower right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3_0XF46ckWmP"
   },
   "source": [
    "Model loss and accuracy:\n",
    "  On training set:\n",
    "  loss: 0.3821 - acc: 0.9177 \n",
    "  On Validation set:\n",
    "  val_loss: 1.9712 - val_acc: 0.5968"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 493
    },
    "colab_type": "code",
    "id": "6pDsNCI9T861",
    "outputId": "689ebc5b-3bb3-401f-8a3d-7c48d3631070"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_26\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_54 (Conv2D)           (None, 64, 64, 32)        2432      \n",
      "_________________________________________________________________\n",
      "batch_normalization_22 (Batc (None, 64, 64, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_52 (MaxPooling (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_55 (Conv2D)           (None, 16, 16, 64)        51264     \n",
      "_________________________________________________________________\n",
      "batch_normalization_23 (Batc (None, 16, 16, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_53 (MaxPooling (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_24 (Flatten)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_72 (Dense)             (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_73 (Dense)             (None, 84)                86100     \n",
      "_________________________________________________________________\n",
      "dense_74 (Dense)             (None, 101)               8585      \n",
      "=================================================================\n",
      "Total params: 1,198,365\n",
      "Trainable params: 1,198,173\n",
      "Non-trainable params: 192\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "####Lenet5- improved\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (5, 5), activation='relu', input_shape=(64, 64, 3), padding='same'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.MaxPooling2D((4, 4),padding='same',strides=4))\n",
    "\n",
    "model.add(layers.Conv2D(64, (5, 5), activation='relu', padding='same'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.MaxPooling2D((4, 4), padding='same',strides=4))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "model.add(Dense(1024, activation='relu',kernel_regularizer=tf.keras.regularizers.l2(0.001)))\n",
    "model.add(Dense(84, activation='relu',kernel_regularizer=tf.keras.regularizers.l2(0.001)))\n",
    "model.add(Dense(101, activation='softmax'))\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "kLsCu_sze2xL",
    "outputId": "5f0f9856-4b38-47d1-d348-99157cb2f91f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7809 samples, validate on 868 samples\n",
      "Epoch 1/100\n",
      "7809/7809 [==============================] - 3s 375us/sample - loss: 5.0163 - acc: 0.2310 - val_loss: 5.6948 - val_acc: 0.1025\n",
      "Epoch 2/100\n",
      "7809/7809 [==============================] - 2s 199us/sample - loss: 4.2704 - acc: 0.3495 - val_loss: 5.6019 - val_acc: 0.0668\n",
      "Epoch 3/100\n",
      "7809/7809 [==============================] - 2s 195us/sample - loss: 3.8416 - acc: 0.4203 - val_loss: 5.3621 - val_acc: 0.2281\n",
      "Epoch 4/100\n",
      "7809/7809 [==============================] - 2s 196us/sample - loss: 3.4633 - acc: 0.4888 - val_loss: 4.9103 - val_acc: 0.3502\n",
      "Epoch 5/100\n",
      "7809/7809 [==============================] - 2s 200us/sample - loss: 3.1297 - acc: 0.5435 - val_loss: 4.3178 - val_acc: 0.4182\n",
      "Epoch 6/100\n",
      "7809/7809 [==============================] - 2s 199us/sample - loss: 2.8310 - acc: 0.5978 - val_loss: 3.7933 - val_acc: 0.4505\n",
      "Epoch 7/100\n",
      "7809/7809 [==============================] - 2s 198us/sample - loss: 2.5721 - acc: 0.6621 - val_loss: 3.4741 - val_acc: 0.4827\n",
      "Epoch 8/100\n",
      "7809/7809 [==============================] - 2s 199us/sample - loss: 2.3705 - acc: 0.6978 - val_loss: 3.2119 - val_acc: 0.5357\n",
      "Epoch 9/100\n",
      "7809/7809 [==============================] - 2s 198us/sample - loss: 2.1474 - acc: 0.7512 - val_loss: 3.1086 - val_acc: 0.5415\n",
      "Epoch 10/100\n",
      "7809/7809 [==============================] - 2s 204us/sample - loss: 1.9617 - acc: 0.7987 - val_loss: 3.0616 - val_acc: 0.5461\n",
      "Epoch 11/100\n",
      "7809/7809 [==============================] - 2s 197us/sample - loss: 1.8150 - acc: 0.8319 - val_loss: 2.9728 - val_acc: 0.5657\n",
      "Epoch 12/100\n",
      "7809/7809 [==============================] - 2s 195us/sample - loss: 1.6833 - acc: 0.8626 - val_loss: 2.9913 - val_acc: 0.5588\n",
      "Epoch 13/100\n",
      "7809/7809 [==============================] - 2s 199us/sample - loss: 1.5521 - acc: 0.8970 - val_loss: 2.9609 - val_acc: 0.5657\n",
      "Epoch 14/100\n",
      "7809/7809 [==============================] - 2s 198us/sample - loss: 1.4494 - acc: 0.9257 - val_loss: 2.9984 - val_acc: 0.5668\n",
      "Epoch 15/100\n",
      "7809/7809 [==============================] - 2s 196us/sample - loss: 1.3638 - acc: 0.9467 - val_loss: 2.9411 - val_acc: 0.5668\n",
      "Epoch 16/100\n",
      "7809/7809 [==============================] - 2s 197us/sample - loss: 1.2849 - acc: 0.9641 - val_loss: 2.9460 - val_acc: 0.5795\n",
      "Epoch 17/100\n",
      "7809/7809 [==============================] - 2s 199us/sample - loss: 1.2244 - acc: 0.9748 - val_loss: 2.9491 - val_acc: 0.5876\n",
      "Epoch 18/100\n",
      "7809/7809 [==============================] - 2s 199us/sample - loss: 1.1662 - acc: 0.9860 - val_loss: 2.9682 - val_acc: 0.5783\n",
      "Epoch 19/100\n",
      "7809/7809 [==============================] - 2s 200us/sample - loss: 1.1248 - acc: 0.9908 - val_loss: 2.9574 - val_acc: 0.5910\n",
      "Epoch 20/100\n",
      "7809/7809 [==============================] - 2s 201us/sample - loss: 1.0926 - acc: 0.9956 - val_loss: 2.9590 - val_acc: 0.5876\n",
      "Epoch 21/100\n",
      "7809/7809 [==============================] - 2s 203us/sample - loss: 1.0637 - acc: 0.9977 - val_loss: 2.9548 - val_acc: 0.5979\n",
      "Epoch 22/100\n",
      "7809/7809 [==============================] - 2s 198us/sample - loss: 1.0357 - acc: 0.9985 - val_loss: 2.9540 - val_acc: 0.5841\n",
      "Epoch 23/100\n",
      "7809/7809 [==============================] - 2s 199us/sample - loss: 1.0186 - acc: 0.9990 - val_loss: 2.9600 - val_acc: 0.5979\n",
      "Epoch 24/100\n",
      "7809/7809 [==============================] - 2s 199us/sample - loss: 0.9994 - acc: 0.9992 - val_loss: 2.9625 - val_acc: 0.6002\n",
      "Epoch 25/100\n",
      "7809/7809 [==============================] - 2s 200us/sample - loss: 0.9816 - acc: 0.9994 - val_loss: 2.9772 - val_acc: 0.5968\n",
      "Epoch 26/100\n",
      "7809/7809 [==============================] - 2s 200us/sample - loss: 0.9640 - acc: 0.9995 - val_loss: 2.9551 - val_acc: 0.5991\n",
      "Epoch 27/100\n",
      "7809/7809 [==============================] - 2s 198us/sample - loss: 0.9485 - acc: 0.9996 - val_loss: 2.9688 - val_acc: 0.6048\n",
      "Epoch 28/100\n",
      "7809/7809 [==============================] - 2s 206us/sample - loss: 0.9366 - acc: 0.9994 - val_loss: 2.9615 - val_acc: 0.5979\n",
      "Epoch 29/100\n",
      "7809/7809 [==============================] - 2s 203us/sample - loss: 0.9224 - acc: 0.9995 - val_loss: 2.9422 - val_acc: 0.6106\n",
      "Epoch 30/100\n",
      "7809/7809 [==============================] - 2s 197us/sample - loss: 0.9051 - acc: 0.9996 - val_loss: 2.9403 - val_acc: 0.6048\n",
      "Epoch 31/100\n",
      "7809/7809 [==============================] - 2s 197us/sample - loss: 0.8906 - acc: 0.9996 - val_loss: 2.9344 - val_acc: 0.6071\n",
      "Epoch 32/100\n",
      "7809/7809 [==============================] - 2s 197us/sample - loss: 0.8770 - acc: 0.9992 - val_loss: 2.9739 - val_acc: 0.6048\n",
      "Epoch 33/100\n",
      "7809/7809 [==============================] - 2s 196us/sample - loss: 0.8642 - acc: 0.9996 - val_loss: 2.9238 - val_acc: 0.5933\n",
      "Epoch 34/100\n",
      "7809/7809 [==============================] - 2s 196us/sample - loss: 0.8590 - acc: 0.9982 - val_loss: 2.9000 - val_acc: 0.6002\n",
      "Epoch 35/100\n",
      "7809/7809 [==============================] - 2s 198us/sample - loss: 0.8329 - acc: 0.9994 - val_loss: 2.8915 - val_acc: 0.6094\n",
      "Epoch 36/100\n",
      "7809/7809 [==============================] - 2s 198us/sample - loss: 0.8198 - acc: 0.9995 - val_loss: 2.8697 - val_acc: 0.6002\n",
      "Epoch 37/100\n",
      "7809/7809 [==============================] - 2s 197us/sample - loss: 0.8021 - acc: 0.9995 - val_loss: 2.8524 - val_acc: 0.6037\n",
      "Epoch 38/100\n",
      "7809/7809 [==============================] - 2s 196us/sample - loss: 0.7879 - acc: 0.9994 - val_loss: 2.8494 - val_acc: 0.6014\n",
      "Epoch 39/100\n",
      "7809/7809 [==============================] - 2s 198us/sample - loss: 0.7722 - acc: 0.9996 - val_loss: 2.8186 - val_acc: 0.6060\n",
      "Epoch 40/100\n",
      "7809/7809 [==============================] - 2s 197us/sample - loss: 0.7566 - acc: 0.9995 - val_loss: 2.8009 - val_acc: 0.6002\n",
      "Epoch 41/100\n",
      "7809/7809 [==============================] - 2s 196us/sample - loss: 0.7407 - acc: 0.9995 - val_loss: 2.8020 - val_acc: 0.6025\n",
      "Epoch 42/100\n",
      "7809/7809 [==============================] - 2s 198us/sample - loss: 0.7258 - acc: 0.9995 - val_loss: 2.7704 - val_acc: 0.6025\n",
      "Epoch 43/100\n",
      "7809/7809 [==============================] - 2s 203us/sample - loss: 0.7094 - acc: 0.9995 - val_loss: 2.7443 - val_acc: 0.6083\n",
      "Epoch 44/100\n",
      "7809/7809 [==============================] - 2s 205us/sample - loss: 0.6943 - acc: 0.9994 - val_loss: 2.7333 - val_acc: 0.6060\n",
      "Epoch 45/100\n",
      "7809/7809 [==============================] - 2s 205us/sample - loss: 0.6779 - acc: 0.9994 - val_loss: 2.6957 - val_acc: 0.6071\n",
      "Epoch 46/100\n",
      "7809/7809 [==============================] - 2s 202us/sample - loss: 0.6618 - acc: 0.9994 - val_loss: 2.7303 - val_acc: 0.6141\n",
      "Epoch 47/100\n",
      "7809/7809 [==============================] - 2s 202us/sample - loss: 0.6482 - acc: 0.9994 - val_loss: 2.6959 - val_acc: 0.6094\n",
      "Epoch 48/100\n",
      "7809/7809 [==============================] - 2s 209us/sample - loss: 0.6290 - acc: 0.9996 - val_loss: 2.6406 - val_acc: 0.6014\n",
      "Epoch 49/100\n",
      "7809/7809 [==============================] - 2s 202us/sample - loss: 0.6135 - acc: 0.9994 - val_loss: 2.7423 - val_acc: 0.5945\n",
      "Epoch 50/100\n",
      "7809/7809 [==============================] - 2s 208us/sample - loss: 0.6652 - acc: 0.9909 - val_loss: 2.7552 - val_acc: 0.6002\n",
      "Epoch 51/100\n",
      "7809/7809 [==============================] - 2s 210us/sample - loss: 0.6056 - acc: 0.9991 - val_loss: 2.6075 - val_acc: 0.6106\n",
      "Epoch 52/100\n",
      "7809/7809 [==============================] - 2s 212us/sample - loss: 0.5804 - acc: 0.9995 - val_loss: 2.5863 - val_acc: 0.6071\n",
      "Epoch 53/100\n",
      "7809/7809 [==============================] - 2s 211us/sample - loss: 0.5635 - acc: 0.9994 - val_loss: 2.5469 - val_acc: 0.6164\n",
      "Epoch 54/100\n",
      "7809/7809 [==============================] - 2s 214us/sample - loss: 0.5472 - acc: 0.9995 - val_loss: 2.5400 - val_acc: 0.6152\n",
      "Epoch 55/100\n",
      "7809/7809 [==============================] - 2s 210us/sample - loss: 0.5335 - acc: 0.9995 - val_loss: 2.5176 - val_acc: 0.6106\n",
      "Epoch 56/100\n",
      "7809/7809 [==============================] - 2s 211us/sample - loss: 0.5173 - acc: 0.9996 - val_loss: 2.5388 - val_acc: 0.6175\n",
      "Epoch 57/100\n",
      "7809/7809 [==============================] - 2s 213us/sample - loss: 0.5027 - acc: 0.9996 - val_loss: 2.4979 - val_acc: 0.6175\n",
      "Epoch 58/100\n",
      "7809/7809 [==============================] - 2s 214us/sample - loss: 0.4886 - acc: 0.9996 - val_loss: 2.5109 - val_acc: 0.6152\n",
      "Epoch 59/100\n",
      "7809/7809 [==============================] - 2s 208us/sample - loss: 0.4876 - acc: 0.9988 - val_loss: 2.4727 - val_acc: 0.6152\n",
      "Epoch 60/100\n",
      "7809/7809 [==============================] - 2s 202us/sample - loss: 0.4657 - acc: 0.9995 - val_loss: 2.4575 - val_acc: 0.6244\n",
      "Epoch 61/100\n",
      "7809/7809 [==============================] - 2s 204us/sample - loss: 0.4524 - acc: 0.9991 - val_loss: 2.4496 - val_acc: 0.6118\n",
      "Epoch 62/100\n",
      "7809/7809 [==============================] - 2s 206us/sample - loss: 0.4379 - acc: 0.9995 - val_loss: 2.4071 - val_acc: 0.6244\n",
      "Epoch 63/100\n",
      "7809/7809 [==============================] - 2s 206us/sample - loss: 0.4233 - acc: 0.9996 - val_loss: 2.3710 - val_acc: 0.6141\n",
      "Epoch 64/100\n",
      "7809/7809 [==============================] - 2s 210us/sample - loss: 0.4108 - acc: 0.9995 - val_loss: 2.3573 - val_acc: 0.6244\n",
      "Epoch 65/100\n",
      "7809/7809 [==============================] - 2s 204us/sample - loss: 0.3992 - acc: 0.9994 - val_loss: 2.3541 - val_acc: 0.6094\n",
      "Epoch 66/100\n",
      "7809/7809 [==============================] - 2s 210us/sample - loss: 0.3874 - acc: 0.9994 - val_loss: 2.3611 - val_acc: 0.6094\n",
      "Epoch 67/100\n",
      "7809/7809 [==============================] - 2s 204us/sample - loss: 0.3730 - acc: 0.9995 - val_loss: 2.3200 - val_acc: 0.6106\n",
      "Epoch 68/100\n",
      "7809/7809 [==============================] - 2s 207us/sample - loss: 0.3615 - acc: 0.9995 - val_loss: 2.3133 - val_acc: 0.6141\n",
      "Epoch 69/100\n",
      "7809/7809 [==============================] - 2s 207us/sample - loss: 0.3497 - acc: 0.9995 - val_loss: 2.3116 - val_acc: 0.6152\n",
      "Epoch 70/100\n",
      "7809/7809 [==============================] - 2s 207us/sample - loss: 0.3377 - acc: 0.9995 - val_loss: 2.2800 - val_acc: 0.6025\n",
      "Epoch 71/100\n",
      "7809/7809 [==============================] - 2s 210us/sample - loss: 0.3272 - acc: 0.9992 - val_loss: 2.2262 - val_acc: 0.6210\n",
      "Epoch 72/100\n",
      "7809/7809 [==============================] - 2s 214us/sample - loss: 0.3153 - acc: 0.9996 - val_loss: 2.2679 - val_acc: 0.6048\n",
      "Epoch 73/100\n",
      "7809/7809 [==============================] - 2s 213us/sample - loss: 0.3581 - acc: 0.9914 - val_loss: 2.6209 - val_acc: 0.5818\n",
      "Epoch 74/100\n",
      "7809/7809 [==============================] - 2s 210us/sample - loss: 0.4056 - acc: 0.9791 - val_loss: 2.6585 - val_acc: 0.5553\n",
      "Epoch 75/100\n",
      "7809/7809 [==============================] - 2s 210us/sample - loss: 0.3574 - acc: 0.9918 - val_loss: 2.3240 - val_acc: 0.6060\n",
      "Epoch 76/100\n",
      "7809/7809 [==============================] - 2s 208us/sample - loss: 0.3070 - acc: 0.9992 - val_loss: 2.2528 - val_acc: 0.6313\n",
      "Epoch 77/100\n",
      "7809/7809 [==============================] - 2s 209us/sample - loss: 0.2952 - acc: 0.9994 - val_loss: 2.2720 - val_acc: 0.6244\n",
      "Epoch 78/100\n",
      "7809/7809 [==============================] - 2s 207us/sample - loss: 0.2874 - acc: 0.9994 - val_loss: 2.2466 - val_acc: 0.6290\n",
      "Epoch 79/100\n",
      "7809/7809 [==============================] - 2s 206us/sample - loss: 0.2819 - acc: 0.9992 - val_loss: 2.2425 - val_acc: 0.6244\n",
      "Epoch 80/100\n",
      "7809/7809 [==============================] - 2s 206us/sample - loss: 0.2753 - acc: 0.9994 - val_loss: 2.1987 - val_acc: 0.6290\n",
      "Epoch 81/100\n",
      "7809/7809 [==============================] - 2s 209us/sample - loss: 0.2678 - acc: 0.9994 - val_loss: 2.1904 - val_acc: 0.6302\n",
      "Epoch 82/100\n",
      "7809/7809 [==============================] - 2s 205us/sample - loss: 0.2616 - acc: 0.9995 - val_loss: 2.1733 - val_acc: 0.6325\n",
      "Epoch 83/100\n",
      "7809/7809 [==============================] - 2s 208us/sample - loss: 0.2544 - acc: 0.9995 - val_loss: 2.1917 - val_acc: 0.6302\n",
      "Epoch 84/100\n",
      "7809/7809 [==============================] - 2s 209us/sample - loss: 0.2486 - acc: 0.9996 - val_loss: 2.1340 - val_acc: 0.6290\n",
      "Epoch 85/100\n",
      "7809/7809 [==============================] - 2s 215us/sample - loss: 0.2444 - acc: 0.9992 - val_loss: 2.1539 - val_acc: 0.6302\n",
      "Epoch 86/100\n",
      "7809/7809 [==============================] - 2s 210us/sample - loss: 0.2370 - acc: 0.9995 - val_loss: 2.1345 - val_acc: 0.6348\n",
      "Epoch 87/100\n",
      "7809/7809 [==============================] - 2s 204us/sample - loss: 0.2304 - acc: 0.9995 - val_loss: 2.1229 - val_acc: 0.6244\n",
      "Epoch 88/100\n",
      "7809/7809 [==============================] - 2s 201us/sample - loss: 0.2266 - acc: 0.9996 - val_loss: 2.1202 - val_acc: 0.6221\n",
      "Epoch 89/100\n",
      "7809/7809 [==============================] - 2s 204us/sample - loss: 0.2219 - acc: 0.9995 - val_loss: 2.1030 - val_acc: 0.6221\n",
      "Epoch 90/100\n",
      "7809/7809 [==============================] - 2s 204us/sample - loss: 0.2148 - acc: 0.9995 - val_loss: 2.1040 - val_acc: 0.6233\n",
      "Epoch 91/100\n",
      "7809/7809 [==============================] - 2s 206us/sample - loss: 0.2094 - acc: 0.9994 - val_loss: 2.0880 - val_acc: 0.6152\n",
      "Epoch 92/100\n",
      "7809/7809 [==============================] - 2s 207us/sample - loss: 0.2032 - acc: 0.9995 - val_loss: 2.0655 - val_acc: 0.6164\n",
      "Epoch 93/100\n",
      "7809/7809 [==============================] - 2s 205us/sample - loss: 0.1980 - acc: 0.9995 - val_loss: 2.0432 - val_acc: 0.6267\n",
      "Epoch 94/100\n",
      "7809/7809 [==============================] - 2s 209us/sample - loss: 0.1930 - acc: 0.9994 - val_loss: 2.0580 - val_acc: 0.6302\n",
      "Epoch 95/100\n",
      "7809/7809 [==============================] - 2s 210us/sample - loss: 0.1887 - acc: 0.9994 - val_loss: 2.0365 - val_acc: 0.6198\n",
      "Epoch 96/100\n",
      "7809/7809 [==============================] - 2s 206us/sample - loss: 0.1971 - acc: 0.9985 - val_loss: 2.0798 - val_acc: 0.6279\n",
      "Epoch 97/100\n",
      "7809/7809 [==============================] - 2s 199us/sample - loss: 0.1831 - acc: 0.9994 - val_loss: 2.0642 - val_acc: 0.6244\n",
      "Epoch 98/100\n",
      "7809/7809 [==============================] - 2s 204us/sample - loss: 0.1765 - acc: 0.9994 - val_loss: 2.0526 - val_acc: 0.6406\n",
      "Epoch 99/100\n",
      "7809/7809 [==============================] - 2s 202us/sample - loss: 0.1707 - acc: 0.9996 - val_loss: 2.0374 - val_acc: 0.6256\n",
      "Epoch 100/100\n",
      "7809/7809 [==============================] - 2s 200us/sample - loss: 0.1661 - acc: 0.9994 - val_loss: 2.0176 - val_acc: 0.6302\n"
     ]
    }
   ],
   "source": [
    "from keras import optimizers\n",
    "from keras.optimizers import Adam\n",
    "opt = keras.optimizers.Adam(learning_rate=0.0001)\n",
    "model.compile(loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "              optimizer=opt,\n",
    "              metrics = ['accuracy'])\n",
    "\n",
    "history = model.fit(X, dummy_y, epochs=100, validation_split=0.1, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "colab_type": "code",
    "id": "PyiJgOjJk2oh",
    "outputId": "25b1748c-17e0-43bc-dac8-7e92633267a2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fe3ac5d57b8>"
      ]
     },
     "execution_count": 81,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEKCAYAAAAfGVI8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "####evaluate model\n",
    "plt.plot(history.history['acc'], label='accuracy')\n",
    "plt.plot(history.history['val_acc'], label = 'val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0, 1])\n",
    "plt.legend(loc='lower right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "l8WBxGTt536o"
   },
   "source": [
    "model loss and accuracy: \n",
    "On training set:loss: 0.1661 - acc: 0.9994 \n",
    "On validation set:\n",
    "val_loss: 2.0176 - val_acc: 0.6302"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 493
    },
    "colab_type": "code",
    "id": "JHY4XOE_kW73",
    "outputId": "e8ac6668-a611-47d7-c941-3d0ff22e7f37"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_28\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_58 (Conv2D)           (None, 60, 60, 32)        2432      \n",
      "_________________________________________________________________\n",
      "batch_normalization_26 (Batc (None, 60, 60, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_56 (MaxPooling (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_59 (Conv2D)           (None, 15, 15, 64)        51264     \n",
      "_________________________________________________________________\n",
      "batch_normalization_27 (Batc (None, 15, 15, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_57 (MaxPooling (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_26 (Flatten)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_78 (Dense)             (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_79 (Dense)             (None, 84)                86100     \n",
      "_________________________________________________________________\n",
      "dense_80 (Dense)             (None, 101)               8585      \n",
      "=================================================================\n",
      "Total params: 1,198,365\n",
      "Trainable params: 1,198,173\n",
      "Non-trainable params: 192\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "####Lenet5-linear\n",
    "\n",
    "model_lin = models.Sequential()\n",
    "model_lin.add(layers.Conv2D(32, (5, 5), activation='linear', input_shape=(64, 64, 3), padding='valid'))\n",
    "model_lin.add(layers.BatchNormalization())\n",
    "model_lin.add(layers.MaxPooling2D((4, 4),padding='same'))\n",
    "\n",
    "model_lin.add(layers.Conv2D(64, (5, 5), activation='linear', padding='same'))\n",
    "model_lin.add(layers.BatchNormalization())\n",
    "model_lin.add(layers.MaxPooling2D((4, 4), padding='same'))\n",
    "\n",
    "model_lin.add(layers.Flatten())\n",
    "model_lin.add(Dense(1024, activation='linear',kernel_regularizer=tf.keras.regularizers.l2(0.001)))\n",
    "model_lin.add(Dense(84, activation='linear',kernel_regularizer=tf.keras.regularizers.l2(0.001)))\n",
    "model_lin.add(Dense(101, activation='softmax'))\n",
    "model_lin.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "EcWXG6H6lUm1",
    "outputId": "164ad407-e666-4a06-9236-a1b515ea1b80"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7809 samples, validate on 868 samples\n",
      "Epoch 1/100\n",
      "7809/7809 [==============================] - 3s 381us/sample - loss: 5.1863 - acc: 0.2402 - val_loss: 5.5264 - val_acc: 0.1671\n",
      "Epoch 2/100\n",
      "7809/7809 [==============================] - 1s 160us/sample - loss: 4.2947 - acc: 0.3623 - val_loss: 5.3437 - val_acc: 0.2051\n",
      "Epoch 3/100\n",
      "7809/7809 [==============================] - 1s 162us/sample - loss: 3.9332 - acc: 0.4164 - val_loss: 5.1636 - val_acc: 0.2200\n",
      "Epoch 4/100\n",
      "7809/7809 [==============================] - 1s 159us/sample - loss: 3.6901 - acc: 0.4564 - val_loss: 4.9944 - val_acc: 0.2350\n",
      "Epoch 5/100\n",
      "7809/7809 [==============================] - 1s 161us/sample - loss: 3.4931 - acc: 0.4908 - val_loss: 4.8468 - val_acc: 0.2396\n",
      "Epoch 6/100\n",
      "7809/7809 [==============================] - 1s 161us/sample - loss: 3.3517 - acc: 0.5179 - val_loss: 4.6586 - val_acc: 0.2673\n",
      "Epoch 7/100\n",
      "7809/7809 [==============================] - 1s 162us/sample - loss: 3.1953 - acc: 0.5499 - val_loss: 4.4866 - val_acc: 0.3030\n",
      "Epoch 8/100\n",
      "7809/7809 [==============================] - 1s 162us/sample - loss: 3.0744 - acc: 0.5741 - val_loss: 4.2284 - val_acc: 0.3548\n",
      "Epoch 9/100\n",
      "7809/7809 [==============================] - 1s 162us/sample - loss: 2.9609 - acc: 0.5984 - val_loss: 4.0300 - val_acc: 0.4032\n",
      "Epoch 10/100\n",
      "7809/7809 [==============================] - 1s 161us/sample - loss: 2.8554 - acc: 0.6221 - val_loss: 3.8452 - val_acc: 0.4113\n",
      "Epoch 11/100\n",
      "7809/7809 [==============================] - 1s 161us/sample - loss: 2.7651 - acc: 0.6353 - val_loss: 3.6695 - val_acc: 0.4597\n",
      "Epoch 12/100\n",
      "7809/7809 [==============================] - 1s 161us/sample - loss: 2.6720 - acc: 0.6528 - val_loss: 3.4877 - val_acc: 0.4977\n",
      "Epoch 13/100\n",
      "7809/7809 [==============================] - 1s 161us/sample - loss: 2.5872 - acc: 0.6773 - val_loss: 3.3372 - val_acc: 0.5127\n",
      "Epoch 14/100\n",
      "7809/7809 [==============================] - 1s 160us/sample - loss: 2.5119 - acc: 0.6891 - val_loss: 3.2345 - val_acc: 0.5265\n",
      "Epoch 15/100\n",
      "7809/7809 [==============================] - 1s 163us/sample - loss: 2.4429 - acc: 0.7038 - val_loss: 3.1759 - val_acc: 0.5265\n",
      "Epoch 16/100\n",
      "7809/7809 [==============================] - 1s 163us/sample - loss: 2.3822 - acc: 0.7175 - val_loss: 3.0334 - val_acc: 0.5565\n",
      "Epoch 17/100\n",
      "7809/7809 [==============================] - 1s 165us/sample - loss: 2.3267 - acc: 0.7299 - val_loss: 2.9803 - val_acc: 0.5634\n",
      "Epoch 18/100\n",
      "7809/7809 [==============================] - 1s 162us/sample - loss: 2.2627 - acc: 0.7449 - val_loss: 2.9369 - val_acc: 0.5622\n",
      "Epoch 19/100\n",
      "7809/7809 [==============================] - 1s 165us/sample - loss: 2.1891 - acc: 0.7630 - val_loss: 2.9283 - val_acc: 0.5772\n",
      "Epoch 20/100\n",
      "7809/7809 [==============================] - 1s 159us/sample - loss: 2.1388 - acc: 0.7731 - val_loss: 2.8392 - val_acc: 0.5795\n",
      "Epoch 21/100\n",
      "7809/7809 [==============================] - 1s 160us/sample - loss: 2.1018 - acc: 0.7773 - val_loss: 2.8146 - val_acc: 0.5910\n",
      "Epoch 22/100\n",
      "7809/7809 [==============================] - 1s 160us/sample - loss: 2.0542 - acc: 0.7918 - val_loss: 2.7522 - val_acc: 0.5991\n",
      "Epoch 23/100\n",
      "7809/7809 [==============================] - 1s 160us/sample - loss: 1.9831 - acc: 0.8106 - val_loss: 2.7349 - val_acc: 0.6037\n",
      "Epoch 24/100\n",
      "7809/7809 [==============================] - 1s 158us/sample - loss: 1.9405 - acc: 0.8242 - val_loss: 2.7244 - val_acc: 0.6106\n",
      "Epoch 25/100\n",
      "7809/7809 [==============================] - 1s 159us/sample - loss: 1.9272 - acc: 0.8193 - val_loss: 2.7085 - val_acc: 0.6313\n",
      "Epoch 26/100\n",
      "7809/7809 [==============================] - 1s 156us/sample - loss: 1.8716 - acc: 0.8371 - val_loss: 2.6864 - val_acc: 0.6164\n",
      "Epoch 27/100\n",
      "7809/7809 [==============================] - 1s 158us/sample - loss: 1.8432 - acc: 0.8399 - val_loss: 2.7031 - val_acc: 0.6233\n",
      "Epoch 28/100\n",
      "7809/7809 [==============================] - 1s 157us/sample - loss: 1.7955 - acc: 0.8573 - val_loss: 2.6361 - val_acc: 0.6141\n",
      "Epoch 29/100\n",
      "7809/7809 [==============================] - 1s 159us/sample - loss: 1.7527 - acc: 0.8704 - val_loss: 2.6215 - val_acc: 0.6267\n",
      "Epoch 30/100\n",
      "7809/7809 [==============================] - 1s 157us/sample - loss: 1.7263 - acc: 0.8728 - val_loss: 2.6496 - val_acc: 0.6244\n",
      "Epoch 31/100\n",
      "7809/7809 [==============================] - 1s 158us/sample - loss: 1.7177 - acc: 0.8708 - val_loss: 2.5810 - val_acc: 0.6394\n",
      "Epoch 32/100\n",
      "7809/7809 [==============================] - 1s 158us/sample - loss: 1.6724 - acc: 0.8849 - val_loss: 2.5955 - val_acc: 0.6359\n",
      "Epoch 33/100\n",
      "7809/7809 [==============================] - 1s 161us/sample - loss: 1.6769 - acc: 0.8776 - val_loss: 2.5512 - val_acc: 0.6544\n",
      "Epoch 34/100\n",
      "7809/7809 [==============================] - 1s 159us/sample - loss: 1.6200 - acc: 0.8961 - val_loss: 2.5762 - val_acc: 0.6371\n",
      "Epoch 35/100\n",
      "7809/7809 [==============================] - 1s 160us/sample - loss: 1.5997 - acc: 0.9029 - val_loss: 2.5647 - val_acc: 0.6486\n",
      "Epoch 36/100\n",
      "7809/7809 [==============================] - 1s 162us/sample - loss: 1.5620 - acc: 0.9138 - val_loss: 2.5596 - val_acc: 0.6521\n",
      "Epoch 37/100\n",
      "7809/7809 [==============================] - 1s 161us/sample - loss: 1.5389 - acc: 0.9161 - val_loss: 2.5230 - val_acc: 0.6509\n",
      "Epoch 38/100\n",
      "7809/7809 [==============================] - 1s 159us/sample - loss: 1.5019 - acc: 0.9253 - val_loss: 2.5271 - val_acc: 0.6578\n",
      "Epoch 39/100\n",
      "7809/7809 [==============================] - 1s 159us/sample - loss: 1.4860 - acc: 0.9298 - val_loss: 2.5309 - val_acc: 0.6429\n",
      "Epoch 40/100\n",
      "7809/7809 [==============================] - 1s 158us/sample - loss: 1.4662 - acc: 0.9346 - val_loss: 2.5760 - val_acc: 0.6406\n",
      "Epoch 41/100\n",
      "7809/7809 [==============================] - 1s 160us/sample - loss: 1.4545 - acc: 0.9344 - val_loss: 2.4958 - val_acc: 0.6694\n",
      "Epoch 42/100\n",
      "7809/7809 [==============================] - 1s 157us/sample - loss: 1.4141 - acc: 0.9463 - val_loss: 2.4884 - val_acc: 0.6647\n",
      "Epoch 43/100\n",
      "7809/7809 [==============================] - 1s 161us/sample - loss: 1.3965 - acc: 0.9499 - val_loss: 2.5029 - val_acc: 0.6544\n",
      "Epoch 44/100\n",
      "7809/7809 [==============================] - 1s 158us/sample - loss: 1.3890 - acc: 0.9488 - val_loss: 2.5024 - val_acc: 0.6590\n",
      "Epoch 45/100\n",
      "7809/7809 [==============================] - 1s 159us/sample - loss: 1.3694 - acc: 0.9535 - val_loss: 2.4734 - val_acc: 0.6601\n",
      "Epoch 46/100\n",
      "7809/7809 [==============================] - 1s 157us/sample - loss: 1.3620 - acc: 0.9547 - val_loss: 2.4791 - val_acc: 0.6636\n",
      "Epoch 47/100\n",
      "7809/7809 [==============================] - 1s 165us/sample - loss: 1.3640 - acc: 0.9449 - val_loss: 2.4634 - val_acc: 0.6717\n",
      "Epoch 48/100\n",
      "7809/7809 [==============================] - 1s 161us/sample - loss: 1.3314 - acc: 0.9585 - val_loss: 2.4737 - val_acc: 0.6717\n",
      "Epoch 49/100\n",
      "7809/7809 [==============================] - 1s 159us/sample - loss: 1.2976 - acc: 0.9686 - val_loss: 2.4760 - val_acc: 0.6694\n",
      "Epoch 50/100\n",
      "7809/7809 [==============================] - 1s 158us/sample - loss: 1.2821 - acc: 0.9712 - val_loss: 2.4946 - val_acc: 0.6601\n",
      "Epoch 51/100\n",
      "7809/7809 [==============================] - 1s 160us/sample - loss: 1.2782 - acc: 0.9681 - val_loss: 2.4715 - val_acc: 0.6578\n",
      "Epoch 52/100\n",
      "7809/7809 [==============================] - 1s 157us/sample - loss: 1.2531 - acc: 0.9757 - val_loss: 2.4414 - val_acc: 0.6717\n",
      "Epoch 53/100\n",
      "7809/7809 [==============================] - 1s 158us/sample - loss: 1.2566 - acc: 0.9704 - val_loss: 2.4477 - val_acc: 0.6613\n",
      "Epoch 54/100\n",
      "7809/7809 [==============================] - 1s 158us/sample - loss: 1.2366 - acc: 0.9755 - val_loss: 2.4655 - val_acc: 0.6613\n",
      "Epoch 55/100\n",
      "7809/7809 [==============================] - 1s 156us/sample - loss: 1.2232 - acc: 0.9799 - val_loss: 2.4465 - val_acc: 0.6682\n",
      "Epoch 56/100\n",
      "7809/7809 [==============================] - 1s 157us/sample - loss: 1.1979 - acc: 0.9839 - val_loss: 2.4284 - val_acc: 0.6636\n",
      "Epoch 57/100\n",
      "7809/7809 [==============================] - 1s 159us/sample - loss: 1.1806 - acc: 0.9863 - val_loss: 2.4239 - val_acc: 0.6786\n",
      "Epoch 58/100\n",
      "7809/7809 [==============================] - 1s 159us/sample - loss: 1.1790 - acc: 0.9857 - val_loss: 2.4130 - val_acc: 0.6717\n",
      "Epoch 59/100\n",
      "7809/7809 [==============================] - 1s 161us/sample - loss: 1.1802 - acc: 0.9839 - val_loss: 2.4305 - val_acc: 0.6728\n",
      "Epoch 60/100\n",
      "7809/7809 [==============================] - 1s 158us/sample - loss: 1.1601 - acc: 0.9868 - val_loss: 2.4363 - val_acc: 0.6694\n",
      "Epoch 61/100\n",
      "7809/7809 [==============================] - 1s 158us/sample - loss: 1.1435 - acc: 0.9885 - val_loss: 2.4124 - val_acc: 0.6797\n",
      "Epoch 62/100\n",
      "7809/7809 [==============================] - 1s 159us/sample - loss: 1.1295 - acc: 0.9917 - val_loss: 2.4416 - val_acc: 0.6659\n",
      "Epoch 63/100\n",
      "7809/7809 [==============================] - 1s 156us/sample - loss: 1.1409 - acc: 0.9863 - val_loss: 2.4065 - val_acc: 0.6717\n",
      "Epoch 64/100\n",
      "7809/7809 [==============================] - 1s 159us/sample - loss: 1.1298 - acc: 0.9881 - val_loss: 2.4205 - val_acc: 0.6613\n",
      "Epoch 65/100\n",
      "7809/7809 [==============================] - 1s 158us/sample - loss: 1.1062 - acc: 0.9910 - val_loss: 2.3978 - val_acc: 0.6751\n",
      "Epoch 66/100\n",
      "7809/7809 [==============================] - 1s 158us/sample - loss: 1.1010 - acc: 0.9922 - val_loss: 2.4271 - val_acc: 0.6751\n",
      "Epoch 67/100\n",
      "7809/7809 [==============================] - 1s 159us/sample - loss: 1.0794 - acc: 0.9945 - val_loss: 2.3868 - val_acc: 0.6820\n",
      "Epoch 68/100\n",
      "7809/7809 [==============================] - 1s 158us/sample - loss: 1.0787 - acc: 0.9932 - val_loss: 2.3879 - val_acc: 0.6774\n",
      "Epoch 69/100\n",
      "7809/7809 [==============================] - 1s 157us/sample - loss: 1.0645 - acc: 0.9954 - val_loss: 2.3785 - val_acc: 0.6820\n",
      "Epoch 70/100\n",
      "7809/7809 [==============================] - 1s 160us/sample - loss: 1.0521 - acc: 0.9962 - val_loss: 2.3712 - val_acc: 0.6763\n",
      "Epoch 71/100\n",
      "7809/7809 [==============================] - 1s 159us/sample - loss: 1.0435 - acc: 0.9971 - val_loss: 2.3725 - val_acc: 0.6774\n",
      "Epoch 72/100\n",
      "7809/7809 [==============================] - 1s 164us/sample - loss: 1.0356 - acc: 0.9969 - val_loss: 2.3861 - val_acc: 0.6740\n",
      "Epoch 73/100\n",
      "7809/7809 [==============================] - 1s 157us/sample - loss: 1.0249 - acc: 0.9974 - val_loss: 2.3594 - val_acc: 0.6820\n",
      "Epoch 74/100\n",
      "7809/7809 [==============================] - 1s 160us/sample - loss: 1.0184 - acc: 0.9981 - val_loss: 2.3467 - val_acc: 0.6832\n",
      "Epoch 75/100\n",
      "7809/7809 [==============================] - 1s 161us/sample - loss: 1.0106 - acc: 0.9977 - val_loss: 2.3292 - val_acc: 0.6878\n",
      "Epoch 76/100\n",
      "7809/7809 [==============================] - 1s 160us/sample - loss: 1.0075 - acc: 0.9972 - val_loss: 2.3459 - val_acc: 0.6763\n",
      "Epoch 77/100\n",
      "7809/7809 [==============================] - 1s 160us/sample - loss: 0.9939 - acc: 0.9985 - val_loss: 2.3323 - val_acc: 0.6889\n",
      "Epoch 78/100\n",
      "7809/7809 [==============================] - 1s 160us/sample - loss: 0.9859 - acc: 0.9985 - val_loss: 2.3337 - val_acc: 0.6889\n",
      "Epoch 79/100\n",
      "7809/7809 [==============================] - 1s 159us/sample - loss: 0.9754 - acc: 0.9988 - val_loss: 2.3469 - val_acc: 0.6889\n",
      "Epoch 80/100\n",
      "7809/7809 [==============================] - 1s 159us/sample - loss: 0.9741 - acc: 0.9986 - val_loss: 2.4081 - val_acc: 0.6705\n",
      "Epoch 81/100\n",
      "7809/7809 [==============================] - 1s 160us/sample - loss: 0.9761 - acc: 0.9971 - val_loss: 2.3174 - val_acc: 0.6820\n",
      "Epoch 82/100\n",
      "7809/7809 [==============================] - 1s 162us/sample - loss: 0.9721 - acc: 0.9964 - val_loss: 2.3294 - val_acc: 0.6809\n",
      "Epoch 83/100\n",
      "7809/7809 [==============================] - 1s 160us/sample - loss: 0.9486 - acc: 0.9982 - val_loss: 2.3070 - val_acc: 0.6878\n",
      "Epoch 84/100\n",
      "7809/7809 [==============================] - 1s 163us/sample - loss: 0.9387 - acc: 0.9990 - val_loss: 2.3285 - val_acc: 0.6832\n",
      "Epoch 85/100\n",
      "7809/7809 [==============================] - 1s 165us/sample - loss: 0.9320 - acc: 0.9988 - val_loss: 2.2957 - val_acc: 0.6797\n",
      "Epoch 86/100\n",
      "7809/7809 [==============================] - 1s 163us/sample - loss: 0.9199 - acc: 0.9992 - val_loss: 2.3173 - val_acc: 0.6855\n",
      "Epoch 87/100\n",
      "7809/7809 [==============================] - 1s 160us/sample - loss: 0.9170 - acc: 0.9990 - val_loss: 2.3052 - val_acc: 0.6970\n",
      "Epoch 88/100\n",
      "7809/7809 [==============================] - 1s 159us/sample - loss: 0.9079 - acc: 0.9991 - val_loss: 2.2886 - val_acc: 0.6855\n",
      "Epoch 89/100\n",
      "7809/7809 [==============================] - 1s 162us/sample - loss: 0.9038 - acc: 0.9988 - val_loss: 2.2657 - val_acc: 0.6866\n",
      "Epoch 90/100\n",
      "7809/7809 [==============================] - 1s 159us/sample - loss: 0.8892 - acc: 0.9995 - val_loss: 2.2802 - val_acc: 0.6855\n",
      "Epoch 91/100\n",
      "7809/7809 [==============================] - 1s 164us/sample - loss: 0.8844 - acc: 0.9999 - val_loss: 2.2841 - val_acc: 0.6832\n",
      "Epoch 92/100\n",
      "7809/7809 [==============================] - 1s 160us/sample - loss: 0.8821 - acc: 0.9988 - val_loss: 2.2586 - val_acc: 0.6866\n",
      "Epoch 93/100\n",
      "7809/7809 [==============================] - 1s 160us/sample - loss: 0.8690 - acc: 0.9994 - val_loss: 2.2545 - val_acc: 0.6820\n",
      "Epoch 94/100\n",
      "7809/7809 [==============================] - 1s 161us/sample - loss: 0.8599 - acc: 0.9995 - val_loss: 2.2413 - val_acc: 0.6832\n",
      "Epoch 95/100\n",
      "7809/7809 [==============================] - 1s 165us/sample - loss: 0.8633 - acc: 0.9977 - val_loss: 2.2412 - val_acc: 0.6809\n",
      "Epoch 96/100\n",
      "7809/7809 [==============================] - 1s 161us/sample - loss: 0.8527 - acc: 0.9986 - val_loss: 2.2447 - val_acc: 0.6855\n",
      "Epoch 97/100\n",
      "7809/7809 [==============================] - 1s 157us/sample - loss: 0.8386 - acc: 0.9996 - val_loss: 2.2396 - val_acc: 0.6820\n",
      "Epoch 98/100\n",
      "7809/7809 [==============================] - 1s 160us/sample - loss: 0.8405 - acc: 0.9980 - val_loss: 2.2192 - val_acc: 0.6855\n",
      "Epoch 99/100\n",
      "7809/7809 [==============================] - 1s 159us/sample - loss: 0.8223 - acc: 0.9996 - val_loss: 2.2299 - val_acc: 0.6786\n",
      "Epoch 100/100\n",
      "7809/7809 [==============================] - 1s 159us/sample - loss: 0.8153 - acc: 0.9994 - val_loss: 2.1906 - val_acc: 0.6935\n"
     ]
    }
   ],
   "source": [
    "from keras import optimizers\n",
    "from keras.optimizers import Adam\n",
    "opt = keras.optimizers.Adam(learning_rate=0.0001)\n",
    "model_lin.compile(loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "              optimizer=opt,\n",
    "              metrics = ['accuracy'])\n",
    "\n",
    "history = model_lin.fit(X, dummy_y, epochs=100, validation_split=0.1, batch_size = 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aBYkoqCG_Fs5"
   },
   "source": [
    "Training and validation loss before changing activation function: 0.1661, 2.0176 \n",
    "Training and validation loss before changing activation function: 0.8153, 2.1906\n",
    "\n",
    "As we can see, the training and validation loss increases after changing activation function to linear. This cannot be compensated by adding more convolutional layers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 251
    },
    "colab_type": "code",
    "id": "-j2-mFHhAvQl",
    "outputId": "907db732-fdb8-40aa-83bb-7b00fb242194"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABhQAAADWCAYAAAA5HGjxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
      "text/plain": [
       "<Figure size 2160x2160 with 32 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "####visualize weights\n",
    "from matplotlib import pyplot\n",
    "filters, biases = model_base.layers[0].get_weights()\n",
    "# normalize filter values to 0-1 so we can visualize them\n",
    "f_min, f_max = filters.min(), filters.max()\n",
    "filters = (filters - f_min) / (f_max - f_min)\n",
    "# plot first few filters\n",
    "n_filters, ix = 32, 1\n",
    "pyplot.figure(figsize=(30,30))\n",
    "for i in range(n_filters):\n",
    "  f = filters[:, :, :, i]\n",
    "  ax = pyplot.subplot(n_filters,8, ix)\n",
    "  ax.set_xticks([])\n",
    "  ax.set_yticks([])\n",
    "  pyplot.imshow(f[:, :, 1])\n",
    "  ix +=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DKQZpE7SLr6X"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Assignment2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
